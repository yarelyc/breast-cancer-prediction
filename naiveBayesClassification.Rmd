---
title: "Breast Cancer prediction using Naive Bayes Classifier"
author: "Karina Pizano"
date: "5/8/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(e1071)
library(rpart)
source("/Users/karinapizano/Documents/Data Mining/lin-regr-util.R")
source("/Users/karinapizano/Documents/Data Mining/class-util.R")
```



###Breast Cancer Prediction
_Data Cleaning and Munging_
```{r }
dat = read.csv("data.csv")

# Create Factors
dat$diagnosis = factor(dat$diagnosis, labels =c("None", "Cancer"))

# Part the data.
data_sets = split_data(dat)
tr_dat = data_sets[[1]]
te_dat = data_sets[[2]]

# Remove bad columns and data.
dat$X = NULL
```

##Data Exploration
_Scatter Plot to detect any correlation between the attributes._
<!-- Scatter plots to detect any correlation, if any -->
```{r}
plot(dat[,c("radius_mean", "texture_mean","perimeter_mean", "concavity_mean")])
```


_We can see more correlation between more attributes_
```{r}
plot(dat[,1:10])
```


_Our data contains a good balance of diagnosis data._
```{r}
barplot(table(dat$diagnosis), names.arg=c("No Cancer", "Cancer"), main="Amount of Cancer and Non Cancer patients", col=c("cyan", "red"))
```



_Whats a popular radius mean when looking at an infected area?_

```{r}
hist(dat$radius_worst, main="Radius Worst", col="cyan", xlab = "radius worst")
```

##Naive Bayes Model
<!-- Naive Bayes Model -->
_Create a Naive Bayes Model_
```{r }
fit = naiveBayes(diagnosis ~ radius_worst + texture_worst + concave.points_worst, data= tr_dat)
```

_Summary of the Model_
```{r }
summary(fit)
```

_Predictions & Confusion Matrix_
```{r}
predictions = predict(fit, newdata=te_dat)
con_matrix = table(te_dat$diagnosis, predictions)
con_matrix
```

_The accuracy of our classifier._
```{r}
accuracy = mean(predictions == te_dat$diagnosis)
accuracy
```

_Precision of the Classifier_
```{r}
con_matrix[2,2] / (con_matrix[2,2] + con_matrix[1,2])
```

_Recall of our Classifier_
```{r}
con_matrix[2,2] / (con_matrix[2,2] + con_matrix[2,1])
```


_Showing the distribution of radius worst when a person is diagnosed with cancer or not diagnosed with the cancer using radius worst. We can see that as the radius worst increases above 15 the changes are higher of being diagnosed with cancer. _
```{r}

plot(density(dat[dat$diagnosis == "None",]$radius_worst), col="cyan", main="Distibution of Radius Worst")
lines(density(dat[dat$diagnosis == "Cancer",]$radius_worst), col="red")
legend(7,0.18,legend =c("Cancer", "No Cancer"), fill=c("red", "cyan"), cex=0.75)

```
<!-- Fitted model Standard deviations and mean using radius_worst when the disease is present and not present -->

_We are looking at the trained distributions for the fitted model, both when the disease IS present and NOT present. Mean and Standard Deviation._
```{r}
fit$tables$radius_worst
```


_Density plot for mean and standard deviation of radius worst._
```{r}
plot(density(fit$tables$texture_worst[1,]), col="red", main="Mean & Standard Deviation")
lines(density(fit$tables$texture_worst[2,]), col="cyan")
legend(-7,0.05,legend =c("Stan. Dev.", "Mean"), fill=c("cyan", "red"), cex=0.75)

```


_Density plot for mean and standard deviation of worst texture. Here we can see that when worst texture is around 25 the line between having cancer and not is blurred, but is leaning more on having cancer._
```{r}
plot(density(dat[dat$diagnosis == "None",]$concave.points_worst), col="cyan", main="Mean")
lines(density(dat[dat$diagnosis == "Cancer",]$concave.points_worst), col="red")
legend(10,0.06,legend =c("Cancer", "No Cancer"), fill=c("red", "cyan"), cex=0.75)
```

<!-- ######################################################################## -->

_Let's see how good we are able to predict Breast Cancer using naive bayes conditional probability and then compare it to the e01171 predictor._
```{r}
#Computing features. 
tb = te_dat[1, c("radius_worst", "texture_worst", "concave.points_worst")]

#Compute P(radius_mean | no disease) and p(radius_mean | disease)
prob_no_radius_disease = dnorm(tb$radius_worst,mean=fit$tables$radius_worst[1,1],sd=fit$tables$radius_worst[1,2])
prob_yes_radius_disease = dnorm(tb$radius_worst,mean=fit$tables$radius_worst[2,1],sd=fit$tables$radius_worst[2,2])

#Compute P(texture_worst | no disease) and P(texture_worst | disease)
prob_no_text_disease = dnorm(tb$texture_worst,mean=fit$tables$texture_worst[1,1],sd=fit$tables$texture_worst[1,2])
prob_yes_text_disease = dnorm(tb$texture_worst,mean=fit$tables$texture_worst[2,1],sd=fit$tables$texture_worst[2,2])

#Compute P(concave.points_worst | no disease) and P(concave.points_worst | disease)
prob_no_points_disease = dnorm(tb$concave.points_worst,mean=fit$tables$concave.points_worst[1,1],sd=fit$tables$concave.points_worst[1,2])
prob_yes_points_disease = dnorm(tb$concave.points_worst,mean=fit$tables$concave.points_worst[2,1],sd=fit$tables$concave.points_worst[2,2])

#Probabilities of disease and no disease.
prob_no_disease = fit$apriori[1]
prob_yes_disease = fit$apriori[2]

output = ((prob_no_radius_disease * prob_no_text_disease * prob_no_points_disease * prob_no_disease) / (prob_yes_radius_disease * prob_yes_text_disease * prob_yes_points_disease * prob_yes_disease))
output
```

_Our prediction tells us .._
```{r}

pred = ifelse(output > 1, "No Cancer", "Cancer")
pred
```

_The e01071 says_
```{r}

predict(fit, newdata = tb)
```

<!-- ######################################################################## -->
##Learning Curve for Naive Bayes Classifier
_The learning curves shows, that we have high variance. We need more data to train and test. Overall the errors decrease for both the test and training data._
```{r}

te_errs = c()
tr_errs = c()
te_actual = te_dat$diagnosis
tr_sizes = seq(100, nrow(tr_dat), length.out=10)

for (tr_size in tr_sizes) {
  tr_dat1 = tr_dat[1:tr_size,]
  tr_actual = tr_dat1$diagnosis
  fit = naiveBayes(diagnosis ~ radius_worst + texture_worst + concave.points_worst, data=tr_dat1)
  
  # error on training set
  tr_predicted = predict(fit, tr_dat1, type="class")
  tr_predicted
  err = sum(tr_actual != tr_predicted)/length(tr_predicted)
  tr_errs = c(tr_errs, err)
 
  # error on test set
  te_predicted = predict(fit, te_dat, type="class")
  err = sum(te_actual != te_predicted)/length(te_predicted)
  te_errs = c(te_errs, err)
  te_errs
}

plot(range(tr_sizes), range(te_errs, tr_errs), type='n', xlab='training set size', ylab='error')

lines(tr_sizes, tr_errs, col='green')
lines(tr_sizes, te_errs, col='red')
```


